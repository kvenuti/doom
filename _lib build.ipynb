{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keenan/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "from rap_db import *\n",
    "from rap_clean import*\n",
    "from rap_viz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doom = art_load(['Doom'])['Doom']\n",
    "chief = art_load(['Chief Keef'])['Chief Keef']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "#verse count for each\n",
    "print(len(doom.uniq_art_verses))\n",
    "print(len(chief.uniq_art_verses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class line_data():\n",
    "    def __init__(self, line_obj):\n",
    "        return\n",
    "    #this needs to look at a rap line and pull the white board metrics\n",
    "    #needs to be as fast and simple as possible as it will have to run on every training, testing, and validation data point\n",
    "    def gen_line_metrics(self):\n",
    "        return\n",
    "    \n",
    "    def gen_line_stem(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def art_to_verse_graph(art_obj, inp_pop=False, inp_exc_line=True, inp_opto_type='near'):#opto stuff here\n",
    "    ret_verse_graphs = []\n",
    "    for s in art_obj.songs:\n",
    "        for v in s.uniq_art_verses:\n",
    "            verse_g = verse_graph(v, art_obj.name, s.name)\n",
    "            verse_g.opto_matches(pop=inp_pop, exc_line=inp_exc_line, opto_type=inp_opto_type, record=False)\n",
    "            ret_verse_graphs.append(verse_g)\n",
    "    return ret_verse_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verse_graph_to_lines(verse_graph_obj):\n",
    "    ret_lines = []\n",
    "    for v_line in verse_graph_obj.ver_as_lines:\n",
    "        line_data_obj = line_data(v_line)\n",
    "        ret_lines.append(line_data_obj)\n",
    "    return ret_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2875"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#line_count\n",
    "all_doom_lines = [ver for verse_g in art_to_verse_graph(doom, inp_pop=2, inp_exc_line=False, inp_opto_type='exact') for ver in verse_graph_to_lines(verse_g)]\n",
    "len(all_doom_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chief_lines = [ver for verse_g in art_to_verse_graph(chief, inp_pop=2, inp_exc_line=False, inp_opto_type='exact') for ver in verse_graph_to_lines(verse_g)]\n",
    "len(all_chief_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes all words and makes them into stems\n",
    "#taken from rap clean, needs adjustments as we go\n",
    "from nltk.stem import *\n",
    "def split_on_stem(rap_line):\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    all_words = re.sub(\"[^0-9a-zA-Z\\']+\", ' ', rap_line).split(' ')\n",
    "    words_stm = [stemmer.stem(x.lower()) for x in all_words if stemmer.stem(x.lower()) not in stopwords.words('english')]\n",
    "    self.all_stemmed_words = list(filter(None, words_stm))\n",
    "    self.unique_stemmed_words = set(self.all_stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guide\n",
    "need to take advantage of opto matches from verse graph\n",
    "somehow make verse graph for each verse and just opto matches, then make line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you did\n",
    "shell for line metrics\n",
    "\n",
    "What you need to do next\n",
    "Train models using two different training methadologies\n",
    "1. text bag of words (simply look at words in textand classify using a naive bayes, random forest, SVM)\n",
    "2. make a row for every line based on the whiteboarded lingustic measures (def use svm, maybe random forest, maybe KNN)\n",
    "\n",
    "each artist should have a list of rap_line objects. Each line should have a word object dictionary, the preserved words as list of strings and then stemmed words/with unique stuff\n",
    "\n",
    "Long term"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
