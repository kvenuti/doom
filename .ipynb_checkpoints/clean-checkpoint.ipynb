{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kvenuti\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "import re\n",
    "#import psycopg2 as pg2\n",
    "#let's store in a postgresql db\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualizations to start\n",
    "\n",
    "Sentiment anlaysis for each line for each verse for each song for each album\n",
    "sentiment analysis for each verse for each song for each album\n",
    "sentiment analysis fo reach song for each album\n",
    "http://lotrproject.com/statistics/books/sentimentanalysis\n",
    "http://help.sentiment140.com/api\n",
    "\n",
    "word count for album\n",
    "word count for artist\n",
    "\n",
    "word similarity/diversity count score for each song\n",
    "word similarity score for each album\n",
    "\n",
    "phoneme similarity score for each song\n",
    "phoneme similarity score for each album\n",
    "\n",
    "eventually a full textual representation of matching phoenems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code/functions to build\n",
    "breaks down text to list of words (already have)\n",
    "breaks down list of words into list of list of phonemes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "algorithms/metrics to implemnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a cool project, I'd like to make a cool website to go along with hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "songs = json.load(open('raw_mf_doom.json'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Album': 'Mr. Hood',\n",
      " 'Artist': 'K.M.D.',\n",
      " 'Lyrics': '\\n'\n",
      "           \"[Mr. Hood]  Let's enter this jewerly shop.\\n\"\n",
      "           \"[Zev Love]  Ahc'mon Mr. Piocalles man hook it up\\n\"\n",
      "           \"            14K, def bracelet, you can't beat it kid!\\n\"\n",
      "           '[Piocalles] No I cannot do that.\\n'\n",
      "           '            This is not a pawn shop, this is Piocalles Jewelry!\\n'\n",
      "           '            Ahh, Mr. Hood, my favorite customer!\\n'\n",
      "           '            What can I do for you today?\\n'\n",
      "           '[Mr. Hood]  I would like to see some gold rings.\\n'\n",
      "           '[Piocalles] Ahh yes we have these stupid phat gold rings,\\n'\n",
      "           '            perfect for your masculine hands.\\n'\n",
      "           '[Mr. Hood]  Some earrings for my wife.\\n'\n",
      "           '[Piocalles] How about these elephant studded diamond earrings,\\n'\n",
      "           '            perfect for the woman of your dreams.\\n'\n",
      "           '[Mr. Hood]  And a watch, for my cousin.\\n'\n",
      "           '[Piocalles] Ahh yes we have a Rolex for just under three-thousand\\n'\n",
      "           '            seven-hundred and ninety-two.\\n'\n",
      "           '[Mr. Hood]  That is a beautiful watch.\\n'\n",
      "           \"[Zev Love]  No actually it's two-thousand, three-hundred\\n\"\n",
      "           '            and thirty-six green.\\n'\n",
      "           '[Mr. Hood]  Many thanks for your help.\\n'\n",
      "           \"[Zev Love]  Yeah he's always trying to jerk people!\\n\"\n",
      "           '[Mr. Hood]  My name is Mr. Hood.  What is your name?\\n'\n",
      "           \"[Zev Love]  Hmm... yeah I'm Zev Love X from K.M.D.\\n\"\n",
      "           '[Mr. Hood]  I am pleased to meet you.\\n'\n",
      "           '[Zev Love]  Oh yeah likewise uhh, how ya doin anyway?\\n'\n",
      "           '[Mr. Hood]  Perfectly well, thank you.  And you?\\n'\n",
      "           \"[Zev Love]  Ohh... I'm just chillin, ya see uhh\\n\"\n",
      "           '            but I got one problem.  I come in here to pawn this\\n'\n",
      "           '            bracelet, see cause this rhymin for nickels business\\n'\n",
      "           \"            ain't makin it.  What I need is a job uhh...\\n\"\n",
      "           '            where you work at?  They hiring?\\n'\n",
      "           '[Mr. Hood]  Follow this avenue (yeah) turn right at the corner '\n",
      "           '(uh-huh)\\n'\n",
      "           '            go to the left when you reach the square. (yeah)\\n'\n",
      "           '            It is the house next to the theater.\\n'\n",
      "           \"[Zev Love]  Ohh.  Huh.  Yeah I know the line of work you're in, \"\n",
      "           'yeah.\\n'\n",
      "           '[Mr. Hood]  Would you care for a spoon?  They are not too '\n",
      "           'expensive.\\n'\n",
      "           \"[Zev Love]  No go, I don't deal with that stuff.\\n\"\n",
      "           '            As a matter of fact...\\n'\n",
      "           '\\n'\n",
      "           'This reminds me of the days of dwelling with those who\\n'\n",
      "           'killed off the weak for fancy clothes and hoes too\\n'\n",
      "           'Not opposed to the picket fence dream\\n'\n",
      "           'Where both lines are same side of the gate\\n'\n",
      "           \"It seems that it's all coming back to me now\\n\"\n",
      "           'Yeah ummmmm ahhhhhh I figured it was about two summers ago\\n'\n",
      "           'No joking, no I lie to win\\n'\n",
      "           'Cause it was a crackpot, yeah Crackpot Jenkins\\n'\n",
      "           'I first met Crackpot in like Head Starts\\n'\n",
      "           \"And then I knew he wasn't too head smart cuz I scribbled in art\\n\"\n",
      "           'He insisted on standing in the sandbox to collect unknown\\n'\n",
      "           'amounts of pebbles and stones to throw rocks\\n'\n",
      "           'Dissin the wrist he flicked was suddenly an early physics lesson\\n'\n",
      "           \"Two atoms can't occupy the same space\\n\"\n",
      "           \"at the same time, acknowledged by the playground's boot to wesson\\n\"\n",
      "           'Who felt pops rock then cracked pops face\\n'\n",
      "           'Considering his aim, I warned he could hurt others with his game\\n'\n",
      "           'Ms. Kristmahn warned the same\\n'\n",
      "           \"Although, he didn't care the heat cuz in a decade and one year\\n\"\n",
      "           'He continued to throw rocks for a career\\n'\n",
      "           'Pain and more pain as he pelt rocks felt by\\n'\n",
      "           'Every brother and brown will soon be dealt\\n'\n",
      "           'One more rock thrown, ahh shoot\\n'\n",
      "           'Under the van was a boy in a blue suit\\n'\n",
      "           'Still a lot of rock throwin goin on up the block\\n'\n",
      "           'But a pocket full of pebbles what locked up Crackpot\\n'\n",
      "           \"Should've used his wrists for the cut like Subroc\\n\"\n",
      "           \"Maybe then he'd have avoided the cacophony jackpot\\n\"\n",
      "           'Yeah, the phony jackpot\\n'\n",
      "           '\\n'\n",
      "           '[Zev Love]  Yo man, we got much better things to do with your '\n",
      "           'time\\n'\n",
      "           '[Mr. Hood]  Show me something better\\n'\n",
      "           '[Zev Love]  What, something better?  We built this place man.\\n'\n",
      "           \"            We're the Gods of the Universe, Kings and Queens\\n\"\n",
      "           '            of the planet.\\n'\n",
      "           '(If you or I could see this individual, we might call him an\\n'\n",
      "           ' impractical dreamer, or a crackpot.)\\n'\n",
      "           \"[Zev Love]  No, I'm not crackpot.\\n\"\n",
      "           '(Would you have seen the scientific, intellectual, creative\\n'\n",
      "           ' genius, in a small ragged negro boy?)\\n'\n",
      "           \"[Zev Love]  Uh-oh, uh-oh, ohh no.  You're gonna set it off!\\n\",\n",
      " 'Title': 'Mr. Hood at Piocalles Jewelry/Crackpot'}\n"
     ]
    }
   ],
   "source": [
    "pprint(songs['Songs'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "when I was going to do list of words\n",
    "\n",
    "def clean_lyrics(full_text):\n",
    "    line_list = []\n",
    "    #split on /n so that each entry in list is a line\n",
    "    lines = full_text.split('\\n')\n",
    "    #then make list of words for each line\n",
    "    for line in lines:\n",
    "        #keeps all words\n",
    "        #get rid of all brackets and parenthesees in words (represents someone talking)\n",
    "        words = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\", line)\n",
    "        #isolate words \n",
    "        words = re.findall(r\"[\\w']+\", words)\n",
    "        if len(words):\n",
    "            line_list.append(words)\n",
    "    return line_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_lyrics(full_text):\n",
    "    words = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\", full_text)\n",
    "    words = re.sub(\"\\n\",\"--\",words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = clean_lyrics(songs['Songs'][100]['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "album_dic = {}\n",
    "\n",
    "for song in songs['Songs']:   \n",
    "    try:\n",
    "        if album_dic.get(song['Album']) == None:\n",
    "            album_dic[song['Album']] = {}\n",
    "        else:\n",
    "            album_dic[song['Album']][song['Title']] = {'artist':song['Artist'],'lyrics':clean_lyrics(song['Lyrics'])}\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\kvenuti/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvenuti\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvenuti\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvenuti\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-692ab1be5d06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\"the dog jumped\"\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \"\"\"\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m     return [token for sent in sentences\n\u001b[0;32m    132\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \"\"\"\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;31m# Load the resource.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m     \u001b[0mopened_resource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    815\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raw'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nltk'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'file'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m         \u001b[1;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    651\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'*'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n%s\\n%s\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource 'tokenizers/punkt/english.pickle' not found.  Please\n  use the NLTK Downloader to obtain the resource:  >>>\n  nltk.download()\n  Searched in:\n    - 'C:\\\\Users\\\\kvenuti/nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvenuti\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvenuti\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\kvenuti\\\\AppData\\\\Roaming\\\\nltk_data'\n    - ''\n**********************************************************************"
     ]
    }
   ],
   "source": [
    "nltk.word_tokenize(album_dic['Madvillainy']['All Caps']['lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "FATAL:  password authentication failed for user \"postgres\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b21b294bf334>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpg2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rap_songs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'postgres'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hulk1994'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\kvenu\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\psycopg2\\__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: FATAL:  password authentication failed for user \"postgres\"\n"
     ]
    }
   ],
   "source": [
    "#need password\n",
    "#conn = pg2.connect(database='rap_songs', user='postgres', password=)\n",
    "#words = re.findall(r\"[\\w']+\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
