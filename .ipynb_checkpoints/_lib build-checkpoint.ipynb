{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rap_db import *\n",
    "from rap_clean import *\n",
    "from rap_viz import line, verse_graph\n",
    "from nltk.stem import *\n",
    "from nltk import pos_tag\n",
    "#import nltk\n",
    "#nltk.download()\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from sklearn.model_selection import train_test_split as tr_ts_spl\n",
    "from sklearn.naive_bayes import MultinomialNB as multi_NB\n",
    "from collections import Counter as cntr\n",
    "import plotly.offline as offline\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doom = art_load(['Doom'])['Doom']\n",
    "chief = art_load(['Chief Keef'])['Chief Keef']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "#verse count for each\n",
    "print(len(doom.uniq_art_verses))\n",
    "print(len(chief.uniq_art_verses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class line_data():\n",
    "    def __init__(self, in_line_obj):\n",
    "        self.line_obj = in_line_obj    \n",
    "        self.gen_line_stem()\n",
    "        self.gen_line_metrics()\n",
    "\n",
    "    #want to run in multinomial and bernouli ways (one with frequency one with there not there binary)\n",
    "    def gen_line_stem(self):\n",
    "        #no uniques, one with and without stems\n",
    "        #keeping a full version just in case\n",
    "        self.all_words = [w.lower() for w in self.line_obj.words_as_strings]\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        words_stm = [stemmer.stem(w) for w in self.all_words if stemmer.stem(w) not in stopwords.words('english')]\n",
    "        self.all_stemmed_words = list(filter(None, words_stm))\n",
    "        \n",
    "    #may want to add stemming if accuracy shitty\n",
    "    def gen_line_metrics(self):\n",
    "        #get the vowel strings needed\n",
    "        ex_vwls = self.line_obj.vowel_sounds\n",
    "        nr_vwls = [v[:2] for v in ex_vwls]\n",
    "        brd_vwls = [v[:1] for v in ex_vwls]\n",
    "        #then vowel sounds for unique words, do it this way to not remake word objects\n",
    "        check = set()\n",
    "        ex_vwls_uniqs = []\n",
    "        for w in self.line_obj.word_objs:\n",
    "            if w.text.lower() not in check:\n",
    "                check = check|{w.text.lower()}\n",
    "                ex_vwls_uniqs.extend(list(zip(*w.matches))[1])\n",
    "        nr_vwls_uniqs = [v[:2] for v in ex_vwls_uniqs]\n",
    "        brd_vwls_uniqs = [v[:1] for v in ex_vwls_uniqs]\n",
    "        \n",
    "        #these are used a lot\n",
    "        wrds = self.line_obj.words_as_strings\n",
    "        unq_wrds = self.line_obj.uniq_words_as_strings\n",
    "        wrd_cnt = len(wrds)\n",
    "        unq_wrd_cnt = len(unq_wrds)\n",
    "        blobs = TextBlob(\" \".join(wrds)).sentiment\n",
    "        \n",
    "        #word based metrics\n",
    "        self.metrics={'avg_wrd_len':sum(map(len,wrds))/wrd_cnt,\n",
    "        'avg_unq_wrd_len':sum(map(len,unq_wrds))/unq_wrd_cnt,\n",
    "        'unq_wrds_rat':unq_wrd_cnt/wrd_cnt,\n",
    "                      \n",
    "        #vowel based metrics\n",
    "            #average vowel sounds per word\n",
    "        'avg_wrd_vwls':len(ex_vwls)/wrd_cnt,\n",
    "            #average vowel sounds per unique word\n",
    "        'avg_unq_wrd_vwls':len(ex_vwls_uniqs)/unq_wrd_cnt,\n",
    "            #average unique vowel sounds per word\n",
    "        'avg_wrd_brd_unq_vwls':len(set(brd_vwls))/wrd_cnt,\n",
    "        'avg_wrd_nr_unq_vwls':len(set(nr_vwls))/wrd_cnt,\n",
    "        'avg_wrd_ex_unq_vwls':len(set(ex_vwls))/wrd_cnt,\n",
    "            #average unique vowel sounds per unique word\n",
    "        'avg_unq_wrd_brd_unq_vwls':len(set(brd_vwls_uniqs))/unq_wrd_cnt,\n",
    "        'avg_unq_wrd_nr_unq_vwls':len(set(nr_vwls_uniqs))/unq_wrd_cnt,\n",
    "        'avg_unq_wrd_ex_unq_vwls':len(set(ex_vwls_uniqs))/unq_wrd_cnt,\n",
    "                      \n",
    "        #specialized metrics\n",
    "        'pol':blobs.polarity,\n",
    "        'subj':blobs.subjectivity,\n",
    "        'uniq_pos_rat': len(set(list(zip(*pos_tag(wrds)))[1]))/wrd_cnt,\n",
    "        'uniq_pos_unq_wrd_rat': len(set(list(zip(*pos_tag(unq_wrds)))[1]))/unq_wrd_cnt}\n",
    "        return self.metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def artist_to_data(art_obj, inp_pop=False, inp_exc_line=True, inp_opto_type='near'):#opto stuff\n",
    "    #sample to get keys for line data metrics, not needed later\n",
    "    _ld = line_data(verse_graph(art_obj.uniq_art_verses[0], '', '').ver_as_lines[0])\n",
    "    metric_df = pd.DataFrame(columns = list(_ld.gen_line_metrics())+['artist'])\n",
    "    lingustic_df = pd.DataFrame(columns=['artist','text','all_text'])\n",
    "    \n",
    "    for v in art_obj.uniq_art_verses:\n",
    "        verse_g = verse_graph(v, art_obj.name, '')\n",
    "        verse_g.opto_matches(pop=inp_pop, exc_line=inp_exc_line, opto_type=inp_opto_type, record=False)#opto verse\n",
    "\n",
    "        for v_line in verse_g.ver_as_lines:\n",
    "            #if the line has actually registered words\n",
    "            if v_line.word_objs:\n",
    "                #make a line_data object from the line object\n",
    "                #metric based\n",
    "                line_data_obj = line_data(v_line)\n",
    "                app_dic = copy(line_data_obj.metrics)\n",
    "                app_dic.update({'artist':art_obj.name})#setup the dictionaries to feed to DF\n",
    "                metric_df = metric_df.append(app_dic, ignore_index=True)\n",
    "                \n",
    "                #lingustic based\n",
    "                #special lingustic data (make)\n",
    "                #here\n",
    "                lingustic_df = lingustic_df.append({'text':line_data_obj.all_stemmed_words, 'all_text':line_data_obj.all_words, 'artist':art_obj.name}, ignore_index=True)  \n",
    "    return metric_df, lingustic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test_validate_split(art_lines, rs1=42, rs2=41):\n",
    "    y = art_lines['artist']\n",
    "    x = art_lines.ix[:, art_lines.columns.difference(['artist'])]\n",
    "    x_tr, _x_ts, y_tr, _y_ts = tr_ts_spl(x, y, test_size=0.4, random_state=rs1)\n",
    "    x_ts, x_vl, y_ts, y_vl = tr_ts_spl(_x_ts, _y_ts, test_size=0.5, random_state=rs2)\n",
    "    return {'x_train':x_tr,'y_train':y_tr,'x_test':x_ts,'y_test':y_ts,'x_val':x_vl,'y_val':y_vl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_plot(corr_df):\n",
    "    col_nms = list(corr_df)\n",
    "    col_nms.remove('artist')\n",
    "    offline.init_notebook_mode(connected=True)\n",
    "    #uses pearson coefficient\n",
    "    trace = go.Heatmap(z=corr_df.corr().round(3).values.tolist(),\n",
    "                       x=col_nms,\n",
    "                       y=col_nms)\n",
    "    playout = go.Layout(title='Global Font', font=dict(size=6))\n",
    "    offline.iplot({'data': [trace], 'layout': playout})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_met, d_lin = artist_to_data(doom, inp_pop=2, inp_exc_line=False, inp_opto_type='exact')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_met, c_lin = artist_to_data(chief, inp_pop=False, inp_exc_line=True, inp_opto_type='near')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "type": "heatmap",
         "x": [
          "avg_wrd_len",
          "avg_unq_wrd_len",
          "unq_wrds_rat",
          "avg_wrd_vwls",
          "avg_unq_wrd_vwls",
          "avg_wrd_brd_unq_vwls",
          "avg_wrd_nr_unq_vwls",
          "avg_wrd_ex_unq_vwls",
          "avg_unq_wrd_brd_unq_vwls",
          "avg_unq_wrd_nr_unq_vwls",
          "avg_unq_wrd_ex_unq_vwls",
          "pol",
          "subj",
          "uniq_pos_rat",
          "uniq_pos_unq_wrd_rat"
         ],
         "y": [
          "avg_wrd_len",
          "avg_unq_wrd_len",
          "unq_wrds_rat",
          "avg_wrd_vwls",
          "avg_unq_wrd_vwls",
          "avg_wrd_brd_unq_vwls",
          "avg_wrd_nr_unq_vwls",
          "avg_wrd_ex_unq_vwls",
          "avg_unq_wrd_brd_unq_vwls",
          "avg_unq_wrd_nr_unq_vwls",
          "avg_unq_wrd_ex_unq_vwls",
          "pol",
          "subj",
          "uniq_pos_rat",
          "uniq_pos_unq_wrd_rat"
         ],
         "z": [
          [
           1,
           0.99,
           0.189,
           0.787,
           0.78,
           0.403,
           0.476,
           0.535,
           0.357,
           0.433,
           0.499,
           0.001,
           -0.011,
           0.158,
           0.088
          ],
          [
           0.99,
           1,
           0.109,
           0.786,
           0.789,
           0.386,
           0.455,
           0.514,
           0.357,
           0.433,
           0.501,
           0,
           -0.016,
           0.121,
           0.082
          ],
          [
           0.189,
           0.109,
           1,
           0.115,
           0.068,
           0.157,
           0.27,
           0.29,
           -0.096,
           -0.016,
           0.011,
           0,
           0.072,
           0.323,
           0.002
          ],
          [
           0.787,
           0.786,
           0.115,
           1,
           0.995,
           0.425,
           0.531,
           0.624,
           0.403,
           0.518,
           0.619,
           -0.005,
           -0.02,
           0.111,
           0.064
          ],
          [
           0.78,
           0.789,
           0.068,
           0.995,
           1,
           0.414,
           0.518,
           0.61,
           0.403,
           0.519,
           0.62,
           -0.006,
           -0.024,
           0.093,
           0.062
          ],
          [
           0.403,
           0.386,
           0.157,
           0.425,
           0.414,
           1,
           0.769,
           0.701,
           0.953,
           0.745,
           0.677,
           0.033,
           -0.077,
           0.289,
           0.248
          ],
          [
           0.476,
           0.455,
           0.27,
           0.531,
           0.518,
           0.769,
           1,
           0.924,
           0.696,
           0.944,
           0.872,
           0.029,
           -0.05,
           0.29,
           0.192
          ],
          [
           0.535,
           0.514,
           0.29,
           0.624,
           0.61,
           0.701,
           0.924,
           1,
           0.623,
           0.861,
           0.938,
           0.03,
           -0.027,
           0.286,
           0.183
          ],
          [
           0.357,
           0.357,
           -0.096,
           0.403,
           0.403,
           0.953,
           0.696,
           0.623,
           1,
           0.762,
           0.684,
           0.033,
           -0.093,
           0.226,
           0.256
          ],
          [
           0.433,
           0.433,
           -0.016,
           0.518,
           0.519,
           0.745,
           0.944,
           0.861,
           0.762,
           1,
           0.913,
           0.028,
           -0.07,
           0.214,
           0.203
          ],
          [
           0.499,
           0.501,
           0.011,
           0.619,
           0.62,
           0.677,
           0.872,
           0.938,
           0.684,
           0.913,
           1,
           0.027,
           -0.047,
           0.212,
           0.194
          ],
          [
           0.001,
           0,
           0,
           -0.005,
           -0.006,
           0.033,
           0.029,
           0.03,
           0.033,
           0.028,
           0.027,
           1,
           0.069,
           0.05,
           0.05
          ],
          [
           -0.011,
           -0.016,
           0.072,
           -0.02,
           -0.024,
           -0.077,
           -0.05,
           -0.027,
           -0.093,
           -0.07,
           -0.047,
           0.069,
           1,
           0.01,
           -0.017
          ],
          [
           0.158,
           0.121,
           0.323,
           0.111,
           0.093,
           0.289,
           0.29,
           0.286,
           0.226,
           0.214,
           0.212,
           0.05,
           0.01,
           1,
           0.578
          ],
          [
           0.088,
           0.082,
           0.002,
           0.064,
           0.062,
           0.248,
           0.192,
           0.183,
           0.256,
           0.203,
           0.194,
           0.05,
           -0.017,
           0.578,
           1
          ]
         ]
        }
       ],
       "layout": {
        "font": {
         "size": 6
        },
        "title": "Global Font"
       }
      },
      "text/html": [
       "<div id=\"60578c92-6cb7-42d1-a5bf-1aee9df01052\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"60578c92-6cb7-42d1-a5bf-1aee9df01052\", [{\"type\": \"heatmap\", \"z\": [[1.0, 0.99, 0.189, 0.787, 0.78, 0.403, 0.476, 0.535, 0.357, 0.433, 0.499, 0.001, -0.011, 0.158, 0.088], [0.99, 1.0, 0.109, 0.786, 0.789, 0.386, 0.455, 0.514, 0.357, 0.433, 0.501, 0.0, -0.016, 0.121, 0.082], [0.189, 0.109, 1.0, 0.115, 0.068, 0.157, 0.27, 0.29, -0.096, -0.016, 0.011, -0.0, 0.072, 0.323, 0.002], [0.787, 0.786, 0.115, 1.0, 0.995, 0.425, 0.531, 0.624, 0.403, 0.518, 0.619, -0.005, -0.02, 0.111, 0.064], [0.78, 0.789, 0.068, 0.995, 1.0, 0.414, 0.518, 0.61, 0.403, 0.519, 0.62, -0.006, -0.024, 0.093, 0.062], [0.403, 0.386, 0.157, 0.425, 0.414, 1.0, 0.769, 0.701, 0.953, 0.745, 0.677, 0.033, -0.077, 0.289, 0.248], [0.476, 0.455, 0.27, 0.531, 0.518, 0.769, 1.0, 0.924, 0.696, 0.944, 0.872, 0.029, -0.05, 0.29, 0.192], [0.535, 0.514, 0.29, 0.624, 0.61, 0.701, 0.924, 1.0, 0.623, 0.861, 0.938, 0.03, -0.027, 0.286, 0.183], [0.357, 0.357, -0.096, 0.403, 0.403, 0.953, 0.696, 0.623, 1.0, 0.762, 0.684, 0.033, -0.093, 0.226, 0.256], [0.433, 0.433, -0.016, 0.518, 0.519, 0.745, 0.944, 0.861, 0.762, 1.0, 0.913, 0.028, -0.07, 0.214, 0.203], [0.499, 0.501, 0.011, 0.619, 0.62, 0.677, 0.872, 0.938, 0.684, 0.913, 1.0, 0.027, -0.047, 0.212, 0.194], [0.001, 0.0, -0.0, -0.005, -0.006, 0.033, 0.029, 0.03, 0.033, 0.028, 0.027, 1.0, 0.069, 0.05, 0.05], [-0.011, -0.016, 0.072, -0.02, -0.024, -0.077, -0.05, -0.027, -0.093, -0.07, -0.047, 0.069, 1.0, 0.01, -0.017], [0.158, 0.121, 0.323, 0.111, 0.093, 0.289, 0.29, 0.286, 0.226, 0.214, 0.212, 0.05, 0.01, 1.0, 0.578], [0.088, 0.082, 0.002, 0.064, 0.062, 0.248, 0.192, 0.183, 0.256, 0.203, 0.194, 0.05, -0.017, 0.578, 1.0]], \"x\": [\"avg_wrd_len\", \"avg_unq_wrd_len\", \"unq_wrds_rat\", \"avg_wrd_vwls\", \"avg_unq_wrd_vwls\", \"avg_wrd_brd_unq_vwls\", \"avg_wrd_nr_unq_vwls\", \"avg_wrd_ex_unq_vwls\", \"avg_unq_wrd_brd_unq_vwls\", \"avg_unq_wrd_nr_unq_vwls\", \"avg_unq_wrd_ex_unq_vwls\", \"pol\", \"subj\", \"uniq_pos_rat\", \"uniq_pos_unq_wrd_rat\"], \"y\": [\"avg_wrd_len\", \"avg_unq_wrd_len\", \"unq_wrds_rat\", \"avg_wrd_vwls\", \"avg_unq_wrd_vwls\", \"avg_wrd_brd_unq_vwls\", \"avg_wrd_nr_unq_vwls\", \"avg_wrd_ex_unq_vwls\", \"avg_unq_wrd_brd_unq_vwls\", \"avg_unq_wrd_nr_unq_vwls\", \"avg_unq_wrd_ex_unq_vwls\", \"pol\", \"subj\", \"uniq_pos_rat\", \"uniq_pos_unq_wrd_rat\"]}], {\"title\": \"Global Font\", \"font\": {\"size\": 6}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"60578c92-6cb7-42d1-a5bf-1aee9df01052\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"60578c92-6cb7-42d1-a5bf-1aee9df01052\", [{\"type\": \"heatmap\", \"z\": [[1.0, 0.99, 0.189, 0.787, 0.78, 0.403, 0.476, 0.535, 0.357, 0.433, 0.499, 0.001, -0.011, 0.158, 0.088], [0.99, 1.0, 0.109, 0.786, 0.789, 0.386, 0.455, 0.514, 0.357, 0.433, 0.501, 0.0, -0.016, 0.121, 0.082], [0.189, 0.109, 1.0, 0.115, 0.068, 0.157, 0.27, 0.29, -0.096, -0.016, 0.011, -0.0, 0.072, 0.323, 0.002], [0.787, 0.786, 0.115, 1.0, 0.995, 0.425, 0.531, 0.624, 0.403, 0.518, 0.619, -0.005, -0.02, 0.111, 0.064], [0.78, 0.789, 0.068, 0.995, 1.0, 0.414, 0.518, 0.61, 0.403, 0.519, 0.62, -0.006, -0.024, 0.093, 0.062], [0.403, 0.386, 0.157, 0.425, 0.414, 1.0, 0.769, 0.701, 0.953, 0.745, 0.677, 0.033, -0.077, 0.289, 0.248], [0.476, 0.455, 0.27, 0.531, 0.518, 0.769, 1.0, 0.924, 0.696, 0.944, 0.872, 0.029, -0.05, 0.29, 0.192], [0.535, 0.514, 0.29, 0.624, 0.61, 0.701, 0.924, 1.0, 0.623, 0.861, 0.938, 0.03, -0.027, 0.286, 0.183], [0.357, 0.357, -0.096, 0.403, 0.403, 0.953, 0.696, 0.623, 1.0, 0.762, 0.684, 0.033, -0.093, 0.226, 0.256], [0.433, 0.433, -0.016, 0.518, 0.519, 0.745, 0.944, 0.861, 0.762, 1.0, 0.913, 0.028, -0.07, 0.214, 0.203], [0.499, 0.501, 0.011, 0.619, 0.62, 0.677, 0.872, 0.938, 0.684, 0.913, 1.0, 0.027, -0.047, 0.212, 0.194], [0.001, 0.0, -0.0, -0.005, -0.006, 0.033, 0.029, 0.03, 0.033, 0.028, 0.027, 1.0, 0.069, 0.05, 0.05], [-0.011, -0.016, 0.072, -0.02, -0.024, -0.077, -0.05, -0.027, -0.093, -0.07, -0.047, 0.069, 1.0, 0.01, -0.017], [0.158, 0.121, 0.323, 0.111, 0.093, 0.289, 0.29, 0.286, 0.226, 0.214, 0.212, 0.05, 0.01, 1.0, 0.578], [0.088, 0.082, 0.002, 0.064, 0.062, 0.248, 0.192, 0.183, 0.256, 0.203, 0.194, 0.05, -0.017, 0.578, 1.0]], \"x\": [\"avg_wrd_len\", \"avg_unq_wrd_len\", \"unq_wrds_rat\", \"avg_wrd_vwls\", \"avg_unq_wrd_vwls\", \"avg_wrd_brd_unq_vwls\", \"avg_wrd_nr_unq_vwls\", \"avg_wrd_ex_unq_vwls\", \"avg_unq_wrd_brd_unq_vwls\", \"avg_unq_wrd_nr_unq_vwls\", \"avg_unq_wrd_ex_unq_vwls\", \"pol\", \"subj\", \"uniq_pos_rat\", \"uniq_pos_unq_wrd_rat\"], \"y\": [\"avg_wrd_len\", \"avg_unq_wrd_len\", \"unq_wrds_rat\", \"avg_wrd_vwls\", \"avg_unq_wrd_vwls\", \"avg_wrd_brd_unq_vwls\", \"avg_wrd_nr_unq_vwls\", \"avg_wrd_ex_unq_vwls\", \"avg_unq_wrd_brd_unq_vwls\", \"avg_unq_wrd_nr_unq_vwls\", \"avg_unq_wrd_ex_unq_vwls\", \"pol\", \"subj\", \"uniq_pos_rat\", \"uniq_pos_unq_wrd_rat\"]}], {\"title\": \"Global Font\", \"font\": {\"size\": 6}}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_plot(d_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kvenuti\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DeprecationWarning:\n",
      "\n",
      "\n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comb_met_data = train_test_validate_split(d_met.append(c_met))\n",
    "comb_lin_data = train_test_validate_split(d_lin.append(c_lin))\n",
    "#https://docs.python.org/dev/library/collections.html#collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65813715455475952"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_mod = SVC()\n",
    "svm_mod.fit(comb_met_data['x_train'], comb_met_data['y_train'])\n",
    "svm_mod.score(comb_met_data['x_test'], comb_met_data['y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you did\n",
    "built correlation plot function\n",
    "\n",
    "\n",
    "What you need to do next\n",
    "set up lingustic training\n",
    "\n",
    "Notes\n",
    "\n",
    "Long term\n",
    "Train models using two different training methadologies\n",
    "1. text bag of words (simply look at words in textand classify using a naive bayes, random forest, SVM)\n",
    "2. make a row for every line based on the whiteboarded lingustic measures (def use svm, maybe random forest, maybe KNN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
