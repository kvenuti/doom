{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rap_db import *\n",
    "from rap_clean import *\n",
    "from rap_viz import line, verse_graph\n",
    "from nltk.stem import *\n",
    "from nltk import pos_tag\n",
    "#import nltk\n",
    "#nltk.download()\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doom = art_load(['Doom'])['Doom']\n",
    "chief = art_load(['Chief Keef'])['Chief Keef']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "#verse count for each\n",
    "print(len(doom.uniq_art_verses))\n",
    "print(len(chief.uniq_art_verses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class line_data():\n",
    "    def __init__(self, in_line_obj):\n",
    "        self.line_obj = in_line_obj    \n",
    "        self.gen_line_stem()\n",
    "        self.gen_line_metrics()\n",
    "\n",
    "    #want to run in multinomial and bernouli ways (one with frequency one with there not there binary)\n",
    "    def gen_line_stem(self):\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        words_stm = [stemmer.stem(w.lower()) for w in self.line_obj.words_as_strings if stemmer.stem(w.lower()) not in stopwords.words('english')]\n",
    "        self.all_stemmed_words = list(filter(None, words_stm))\n",
    "        self.unique_stemmed_words = set(self.all_stemmed_words)\n",
    "        \n",
    "    #may want to add stemming if accuracy shitty\n",
    "    def gen_line_metrics(self):\n",
    "        #get the vowel strings needed\n",
    "        ex_vwls = self.line_obj.vowel_sounds\n",
    "        nr_vwls = [v[:2] for v in ex_vwls]\n",
    "        brd_vwls = [v[:1] for v in ex_vwls]\n",
    "        #then vowel sounds for unique words, do it this way to not remake word objects\n",
    "        check = set()\n",
    "        ex_vwls_uniqs = []\n",
    "        for w in self.line_obj.word_objs:\n",
    "            if w.text.lower() not in check:\n",
    "                check = check|{w.text.lower()}\n",
    "                ex_vwls_uniqs.extend(list(zip(*w.matches))[1])\n",
    "        nr_vwls_uniqs = [v[:2] for v in ex_vwls_uniqs]\n",
    "        brd_vwls_uniqs = [v[:1] for v in ex_vwls_uniqs]\n",
    "        \n",
    "        #these are used a lot\n",
    "        wrds = self.line_obj.words_as_strings\n",
    "        unq_wrds = self.line_obj.uniq_words_as_strings\n",
    "        wrd_cnt = len(wrds)\n",
    "        unq_wrd_cnt = len(unq_wrds)\n",
    "        blobs = TextBlob(\" \".join(wrds)).sentiment\n",
    "        \n",
    "        #word based metrics\n",
    "        self.metrics={'avg_wrd_len':sum(map(len,wrds))/wrd_cnt,\n",
    "        'avg_unq_wrd_len':sum(map(len,unq_wrds))/unq_wrd_cnt,\n",
    "        'unq_wrds_rat':unq_wrd_cnt/wrd_cnt,\n",
    "                      \n",
    "        #vowel based metrics\n",
    "            #average vowel sounds per word\n",
    "        'avg_wrd_vwls':len(ex_vwls)/wrd_cnt,\n",
    "            #average vowel sounds per unique word\n",
    "        'avg_unq_wrd_vwls':len(ex_vwls_uniqs)/unq_wrd_cnt,\n",
    "            #average unique vowel sounds per word\n",
    "        'avg_wrd_brd_unq_vwls':len(set(brd_vwls))/wrd_cnt,\n",
    "        'avg_wrd_nr_unq_vwls':len(set(nr_vwls))/wrd_cnt,\n",
    "        'avg_wrd_ex_unq_vwls':len(set(ex_vwls))/wrd_cnt,\n",
    "            #average unique vowel sounds per unique word\n",
    "        'avg_unq_wrd_brd_unq_vwls':len(set(brd_vwls_uniqs))/unq_wrd_cnt,\n",
    "        'avg_unq_wrd_nr_unq_vwls':len(set(nr_vwls_uniqs))/unq_wrd_cnt,\n",
    "        'avg_unq_wrd_ex_unq_vwls':len(set(ex_vwls_uniqs))/unq_wrd_cnt,\n",
    "                      \n",
    "        #specialized metrics\n",
    "        'pol':blobs.polarity,\n",
    "        'subj':blobs.subjectivity,\n",
    "        'uniq_pos_rat': len(set(list(zip(*pos_tag(wrds)))[1]))/wrd_cnt,\n",
    "        'uniq_pos_unq_wrd_rat': len(set(list(zip(*pos_tag(unq_wrds)))[1]))/unq_wrd_cnt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def art_to_verse_graph(art_obj, inp_pop=False, inp_exc_line=True, inp_opto_type='near'):#opto stuff here\n",
    "    ret_verse_graphs = []\n",
    "    for s in art_obj.songs:\n",
    "        for v in s.uniq_art_verses:\n",
    "            verse_g = verse_graph(v, art_obj.name, s.name)\n",
    "            verse_g.opto_matches(pop=inp_pop, exc_line=inp_exc_line, opto_type=inp_opto_type, record=False)\n",
    "            ret_verse_graphs.append(verse_g)\n",
    "    return ret_verse_graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def verse_graph_to_lines(verse_graph_obj):\n",
    "    ret_lines = []\n",
    "    for v_line in verse_graph_obj.ver_as_lines:\n",
    "        if v_line.word_objs:\n",
    "            line_data_obj = line_data(v_line)\n",
    "            ret_lines.append(line_data_obj)\n",
    "    return ret_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#line_count\n",
    "all_doom_lines = [ver for verse_g in art_to_verse_graph(doom, inp_pop=2, inp_exc_line=False, inp_opto_type='exact') for ver in verse_graph_to_lines(verse_g)]\n",
    "print(len(all_doom_lines))\n",
    "all_chief_lines = [ver for verse_g in art_to_verse_graph(chief, inp_pop=False, inp_exc_line=True, inp_opto_type='near') for ver in verse_graph_to_lines(verse_g)]\n",
    "len(all_chief_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_line_data(lines, art_name):\n",
    "    metric_df = pd.DataFrame(columns = list(lines[0].metrics.keys())+['artist'])\n",
    "    #may not want to use pandas here\n",
    "    lingustic_df = pd.DataFrame(columns=['artist','text','unique_text'])\n",
    "    for l in lines:\n",
    "        app_dic = copy(l.metrics)\n",
    "        app_dic.update({'artist':art_name})\n",
    "        metric_df = metric_df.append(app_dic, ignore_index=True)\n",
    "        lingustic_df = lingustic_df.append({'text':l.all_stemmed_words, 'unique_text':l.unique_stemmed_words, 'artist':art_name}, ignore_index=True)\n",
    "    return metric_df, lingustic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "me, li = create_line_data(all_doom_lines, 'MF Doom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_wrd_len</th>\n",
       "      <th>avg_unq_wrd_len</th>\n",
       "      <th>unq_wrds_rat</th>\n",
       "      <th>avg_wrd_vwls</th>\n",
       "      <th>avg_unq_wrd_vwls</th>\n",
       "      <th>avg_wrd_brd_unq_vwls</th>\n",
       "      <th>avg_wrd_nr_unq_vwls</th>\n",
       "      <th>avg_wrd_ex_unq_vwls</th>\n",
       "      <th>avg_unq_wrd_brd_unq_vwls</th>\n",
       "      <th>avg_unq_wrd_nr_unq_vwls</th>\n",
       "      <th>avg_unq_wrd_ex_unq_vwls</th>\n",
       "      <th>pol</th>\n",
       "      <th>subj</th>\n",
       "      <th>uniq_pos_rat</th>\n",
       "      <th>uniq_pos_unq_wrd_rat</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.625000</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>MF Doom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.083333</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>MF Doom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.875000</td>\n",
       "      <td>4.285714</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>MF Doom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>MF Doom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.111111</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>MF Doom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_wrd_len  avg_unq_wrd_len  unq_wrds_rat  avg_wrd_vwls  avg_unq_wrd_vwls  \\\n",
       "0     3.625000         3.625000         1.000      1.375000          1.375000   \n",
       "1     3.083333         3.083333         1.000      1.083333          1.083333   \n",
       "2     3.875000         4.285714         0.875      1.250000          1.285714   \n",
       "3     3.400000         3.400000         1.000      1.200000          1.200000   \n",
       "4     4.111111         4.111111         1.000      1.222222          1.222222   \n",
       "\n",
       "   avg_wrd_brd_unq_vwls  avg_wrd_nr_unq_vwls  avg_wrd_ex_unq_vwls  \\\n",
       "0              0.500000             0.750000             0.875000   \n",
       "1              0.333333             0.500000             0.500000   \n",
       "2              0.500000             0.875000             0.875000   \n",
       "3              0.400000             0.600000             0.700000   \n",
       "4              0.333333             0.777778             0.888889   \n",
       "\n",
       "   avg_unq_wrd_brd_unq_vwls  avg_unq_wrd_nr_unq_vwls  avg_unq_wrd_ex_unq_vwls  \\\n",
       "0                  0.500000                 0.750000                 0.875000   \n",
       "1                  0.333333                 0.500000                 0.500000   \n",
       "2                  0.571429                 1.000000                 1.000000   \n",
       "3                  0.400000                 0.600000                 0.700000   \n",
       "4                  0.333333                 0.777778                 0.888889   \n",
       "\n",
       "    pol  subj  uniq_pos_rat  uniq_pos_unq_wrd_rat   artist  \n",
       "0 -0.05  0.05      0.875000              0.625000  MF Doom  \n",
       "1  0.35  0.65      0.916667              0.750000  MF Doom  \n",
       "2  0.00  0.00      0.500000              0.714286  MF Doom  \n",
       "3  0.00  0.00      0.800000              0.800000  MF Doom  \n",
       "4  1.00  0.30      0.666667              0.666667  MF Doom  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>text</th>\n",
       "      <th>unique_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MF Doom</td>\n",
       "      <td>[excus, mister, got, sister]</td>\n",
       "      <td>{sister, mister, excus, got}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MF Doom</td>\n",
       "      <td>[kiss, true, got, blister]</td>\n",
       "      <td>{kiss, got, true, blister}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MF Doom</td>\n",
       "      <td>[movi, plot, twist, like, twistler]</td>\n",
       "      <td>{twistler, like, twist, movi, plot}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MF Doom</td>\n",
       "      <td>[need, meat, burn, id, go, sizzler]</td>\n",
       "      <td>{need, sizzler, burn, id, meat, go}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MF Doom</td>\n",
       "      <td>[get, paid, like, biker, best, crank]</td>\n",
       "      <td>{paid, biker, like, best, crank, get}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist                                   text  \\\n",
       "0  MF Doom           [excus, mister, got, sister]   \n",
       "1  MF Doom             [kiss, true, got, blister]   \n",
       "2  MF Doom    [movi, plot, twist, like, twistler]   \n",
       "3  MF Doom    [need, meat, burn, id, go, sizzler]   \n",
       "4  MF Doom  [get, paid, like, biker, best, crank]   \n",
       "\n",
       "                             unique_text  \n",
       "0           {sister, mister, excus, got}  \n",
       "1             {kiss, got, true, blister}  \n",
       "2    {twistler, like, twist, movi, plot}  \n",
       "3    {need, sizzler, burn, id, meat, go}  \n",
       "4  {paid, biker, like, best, crank, get}  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you did\n",
    "both could always use work\n",
    "built stemmer\n",
    "built full metrics method\n",
    "\n",
    "What you need to do next\n",
    "\n",
    "Notes\n",
    "\n",
    "Long term\n",
    "Train models using two different training methadologies\n",
    "1. text bag of words (simply look at words in textand classify using a naive bayes, random forest, SVM)\n",
    "2. make a row for every line based on the whiteboarded lingustic measures (def use svm, maybe random forest, maybe KNN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
